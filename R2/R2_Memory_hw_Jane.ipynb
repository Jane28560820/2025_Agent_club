{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 0.Assignments\n",
        "\n",
        "👾 這個陽春的聊天機器人需要被優化！<br>\n",
        "若是一個對話串不間斷地持續進行，送進去的訊息量會很多，tokens數量也會跟著增加，會需要花比較多費用(💸💸💸)，也可能使模型的回應雜訊比較多而回應受到干擾，所以我們可以優化短期記憶。<br>\n",
        "另外，我們希望優化使用者體驗，我們可以根據聊天的內容整理出使用者的屬性，並在每一次跟使用者聊天時，都能根據這個使用者的狀況給予客製化的回應，因此我們要加入長期記憶的功能！\n",
        "\n",
        "<br>\n",
        "\n",
        "### 1. 短期記憶優化\n",
        "\n",
        "(1) 🔰 [基本版] 在短期記憶中，將chatbot node送入llm的訊息中加入trim的優化機制 (依據適當的tokens數量決定)\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "### 2. 加入長期記憶\n",
        "\n",
        "加入長期記憶，讓聊天機器人能夠記住使用者的資訊（名字、偏好語言、興趣），在下一次對話也能針對同個使用者的資訊，給予個人化的回答。\n",
        "\n",
        "(1) 🔰 [基本版]\n",
        "- chatbot node: 在chatbot node中，將該使用者的資訊取出，讓入prompt中讓llm依據使用者的資訊給予個人化的回答\n",
        "\n",
        "- write_memory node: 在每一次生成回答後，將使用者的資訊整理成一段對使用者的描述(使用llm，給予system prompt做指引，自行設計如何整理、需要整理哪些資訊)，將整理完的資訊整理到store (可跨threads存取的地方)。\n",
        "\n",
        "- config: config從原本的短期記憶只有thread_id, 也要加入user_id\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1H4Y0WplOi6R4Eo06Ac2JA_9TbZa2YaRD\" width=\"100\"/>\n",
        "\n",
        "\n",
        "(2) 👨‍🎓 [進階版]\n",
        "- chatbot node: 可以決定使用者的問題是否需要從長期記憶中取得資訊，以及需要取得什麼資訊\n",
        "- write_memory node: 可以整理成特定格式 (例如：使用with_structured_output，相關概念可以延伸到R3 tool calling內容)。例如：\n",
        "```\n",
        "user_profile = {\n",
        "  \"first_name\": \"XXXX\",\n",
        "  \"last_name\": \"OOO\",\n",
        "  \"preferred_lang\": [\"en\", \"zh-tw\"]\n",
        "}\n",
        "```\n",
        "- 也可以自行將graph結構調整自己喜歡的(增刪不同node, conditional router, ...)\n",
        "<br>\n",
        "備註：基本版是需要大家完成的，進階版可以自行決定是否挑戰，Enjoy the ride! 😎"
      ],
      "metadata": {
        "id": "YzuZTjoZkt7a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.短期記憶"
      ],
      "metadata": {
        "id": "Zprt5eyzemnq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (1) 基本版\n",
        "🔰 [基本版] 在短期記憶中，將chatbot node送入llm的訊息中加入trim的優化機制 (依據適當的tokens數量決定)\n",
        "\n",
        "note: 可以邊做邊看一下trim設定的效果以及內部運作的機制"
      ],
      "metadata": {
        "id": "PZHRs_NSsfnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "!pip install -U langgraph langchain_openai==0.3.15 langchain transformers bitsandbytes langchain-huggingface"
      ],
      "metadata": {
        "id": "m8Ahe-dgr3Qa"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "id": "O08w3UkC_vjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from langchain.chat_models import AzureChatOpenAI\n",
        "\n",
        "# 從 secrets 中讀取值\n",
        "api_key = userdata.get(\"OPENAI_KEY\")\n",
        "api_base = userdata.get(\"OPENAI_BASE\")\n",
        "deployment_name = userdata.get(\"OPENAI_DEPLOY\")\n",
        "\n",
        "# 初始化模型\n",
        "llm_api = AzureChatOpenAI(\n",
        "    openai_api_base=api_base,\n",
        "    openai_api_version=\"2024-08-01-preview\",  # 固定的版本\n",
        "    deployment_name=deployment_name,\n",
        "    openai_api_key=api_key,\n",
        "    temperature=0.3,\n",
        ")\n"
      ],
      "metadata": {
        "id": "OAevsKQ3_foU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1073ffc5-27ce-4e5f-8192-bba70a314e8f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-52002afac48f>:10: LangChainDeprecationWarning: The class `AzureChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import AzureChatOpenAI``.\n",
            "  llm_api = AzureChatOpenAI(\n",
            "/usr/local/lib/python3.11/dist-packages/langchain_community/chat_models/azure_openai.py:174: UserWarning: As of openai>=1.0.0, Azure endpoints should be specified via the `azure_endpoint` param not `openai_api_base` (or alias `base_url`). Updating `openai_api_base` from https://intern-bryan.cognitiveservices.azure.com/ to https://intern-bryan.cognitiveservices.azure.com/openai.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/langchain_community/chat_models/azure_openai.py:181: UserWarning: As of openai>=1.0.0, if `deployment_name` (or alias `azure_deployment`) is specified then `openai_api_base` (or alias `base_url`) should not be. Instead use `deployment_name` (or alias `azure_deployment`) and `azure_endpoint`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/langchain_community/chat_models/azure_openai.py:189: UserWarning: As of openai>=1.0.0, if `openai_api_base` (or alias `base_url`) is specified it is expected to be of the form https://example-resource.azure.openai.com/openai/deployments/example-deployment. Updating https://intern-bryan.cognitiveservices.azure.com/ to https://intern-bryan.cognitiveservices.azure.com/openai.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_core.messages import convert_to_openai_messages, SystemMessage, HumanMessage, AIMessage, BaseMessage\n",
        "from langchain_core.runnables.config import RunnableConfig\n",
        "\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "  \"\"\"\n",
        "  若只有messages, 其實等同於MessageState\n",
        "  這邊保留彈性\n",
        "  \"\"\"\n",
        "  messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
        "\n",
        "def get_token_length(text: str) -> int:\n",
        "    return len(encoding.encode(text))\n",
        "\n",
        "# MAX_TOKENS = 300\n",
        "\n",
        "# 加入對話訊息修剪 (trim messages)\n",
        "def trim_messages(messages: list, max_tokens: int) -> list:\n",
        "    \"\"\"\n",
        "    修剪 messages，使總 token 數不超過 max_tokens。\n",
        "    保留最新的訊息為主（從後往前加），直到達到限制。\n",
        "    \"\"\"\n",
        "    trimmed = []\n",
        "    total_tokens = 0\n",
        "\n",
        "    for msg in reversed(messages):\n",
        "        msg_tokens = get_token_length(msg.content)\n",
        "        if total_tokens + msg_tokens > max_tokens:\n",
        "            break\n",
        "        trimmed.insert(0, msg)\n",
        "        total_tokens += msg_tokens\n",
        "\n",
        "    return trimmed\n",
        "\n",
        "\n",
        "def chatbot(state: State, config: RunnableConfig):\n",
        "    system_prompt = \"你是個只能使用繁體中文回答的助理\"\n",
        "    mode = config[\"configurable\"][\"mode\"]\n",
        "\n",
        "    messages = state[\"messages\"]\n",
        "    trimmed_messages = trim_messages(messages, MAX_TOKENS)  # 修剪長度\n",
        "\n",
        "    if mode == \"local\":\n",
        "        converted = convert_to_openai_messages(trimmed_messages)\n",
        "        system_message = [{\"role\": \"system\", \"content\": system_prompt}]\n",
        "        prompt = tokenizer.apply_chat_template(\n",
        "            system_message + converted,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True\n",
        "        )\n",
        "        response = llm_local.invoke(prompt)\n",
        "        return {\"messages\": [AIMessage(content=response)]}\n",
        "    else:\n",
        "        full_messages = [SystemMessage(content=system_prompt)] + trimmed_messages\n",
        "        if mode == \"openai_api\":\n",
        "            response = llm_api.invoke(full_messages)\n",
        "        elif mode == \"huggingface\":\n",
        "            response = llm_huggingface.invoke(full_messages)\n",
        "        return {\"messages\": [response]}\n",
        "\n",
        "\n",
        "\n",
        "# 建立一個有StateGraph\n",
        "graph_builder = StateGraph(State)\n",
        "#                     node name, 呼叫node時要觸發的邏輯(function or object)\n",
        "graph_builder.add_node(\"chatbot\", chatbot) # 在graph裡面加入chatbot的node\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph_builder.add_edge(\"chatbot\", END)\n",
        "\n",
        "# 加入記憶性\n",
        "memory = MemorySaver()\n",
        "graph = graph_builder.compile(checkpointer=memory)"
      ],
      "metadata": {
        "id": "qZi2lCgs9jtL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stream_graph_updates(user_input: str, config: dict):\n",
        "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}, config):\n",
        "        if \"chatbot\" in event:\n",
        "          for value in event.values():\n",
        "            print(\"Assistant:\", value[\"messages\"][-1].content)"
      ],
      "metadata": {
        "id": "2zGZNV-b9p9p"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 第一次對話 (thread_id: conversation_1)\n",
        "mode = \"openai_api\"\n",
        "config_1 = {\"configurable\": {\"thread_id\": \"conversation_1\", \"mode\": mode}} # thread_id: 對話id\n",
        "MAX_TOKENS = 200\n",
        "\n",
        "while True:\n",
        "  try:\n",
        "    user_input = input(\"User: \")\n",
        "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "      print(\"Goodbye!\")\n",
        "      break\n",
        "    stream_graph_updates(user_input, config_1)\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    break"
      ],
      "metadata": {
        "id": "MU5QKF0h9qAu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "773c72ee-8d3e-40c2-f201-3130c9dbc31e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: 安安你好呀！\n",
            "Assistant: 安安！你好呀！有什麼我可以幫忙的嗎？\n",
            "User: 來聊聊電影！\n",
            "Assistant: 好的！你想聊哪部電影呢？或者有什麼特別的主題或角色想討論的嗎？\n",
            "User: 我很喜歡看宮崎駿的電影唷！\n",
            "Assistant: 宮崎駿的電影真的很棒！他的作品充滿了奇幻的元素和深刻的主題，像是環保、成長和人性等。你最喜歡哪一部電影呢？或者有沒有特別喜歡的角色？\n",
            "User: 我最喜歡霍爾的移動城堡\n",
            "Assistant: 《霍爾的移動城堡》是一部非常美麗的作品！故事中的魔法、愛情以及霍爾和蘇菲之間的關係都讓人感動。你喜歡這部電影的哪個部分呢？或者有什麼特別的感受嗎？\n",
            "User: 我很喜歡霍爾的轉變，你知道嗎？霍爾一開始是美麗的金髮，但是遇見蘇菲之後，變回他最原本的髮色，也暗示了他遇見蘇菲之後變得更像自己！\n",
            "Assistant: 你提到的這一點非常有趣！霍爾的轉變確實象徵著他內心的成長和回歸真實自我的過程。當他與蘇菲的關係逐漸加深時，他不再依賴外表的魅力，而是開始展現出真實的自我，這也讓他變得更加成熟和堅強。這樣的轉變不僅是外在的，也是內心的，讓整個故事更加深刻。你還有其他喜歡的角色或情節嗎？\n",
            "User: 還有還有他的魔法四扇門，原本三個門都是不同的入口，而且都代表著霍爾以三個不同的名字的家，意味著他很害怕被壞人找到選擇躲藏，但遇見蘇菲之後，三扇門變成蘇菲最喜歡的地方，蘇菲的故鄉、漂亮的花園，還有跟蘇菲相遇的荒野，非常浪漫\n",
            "Assistant: 這段描述非常美妙，展現了霍爾與蘇菲之間的深厚情感。霍爾的魔法四扇門不僅是他躲避壞人的工具，更是他心靈的象徵。當三扇門轉變為蘇菲喜愛的地方，這不僅代表著霍爾對蘇菲的愛與信任，也顯示出他願意打開心扉，讓蘇菲進入他的世界。這樣的轉變讓故事充滿了浪漫與希望，也讓人感受到愛情的力量如何改變一個人。這樣的情節設計讓整個故事更加動人，讓讀者對霍爾和蘇菲的關係充滿期待。\n",
            "User: 最喜歡的肯定是他們相遇的時候，霍爾英雄救美，他們一起走在空中的畫面\n",
            "Assistant: 那個場景確實非常感人，霍爾的英雄救美展現了他的勇氣和對愛情的堅持，而他們一起在空中漫步的畫面則充滿了浪漫與夢幻。這種奇幻的設定讓人感受到愛情的力量，也讓整個故事更加動人。你最喜歡這部作品的哪個部分呢？\n",
            "User: 我們先來聊聊別的吧！\n",
            "Assistant: 好的，沒問題！你想聊什麼呢？可以是任何主題，比如電影、書籍、旅行、音樂等等。\n",
            "User: 你還記得我之前跟你說過，我喜歡哪位導演的作品嗎？\n",
            "Assistant: 抱歉，我無法記住之前的對話內容。不過，你可以告訴我你喜歡哪位導演的作品，我們可以一起聊聊他的電影！\n",
            "User: exit\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 易讀版\n",
        "def state_pretty_print(state: State):\n",
        "  for m in state.values[\"messages\"]:\n",
        "    m.pretty_print()"
      ],
      "metadata": {
        "id": "Ae4YZFew9qD7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_pretty_print(graph.get_state(config_1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unYHH6ejCoth",
        "outputId": "c1309bd8-197e-494b-a676-6c5a6dbad33b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "安安你好呀！\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "安安！你好呀！有什麼我可以幫你解答的嗎？\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "我很喜歡看宮崎駿的電影唷！\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "宮崎駿的電影真的很棒！他的作品充滿了奇幻的世界和深刻的情感，像《天空之城》、《龍貓》和《千與千尋》等都是經典之作。你最喜歡哪一部呢？\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "我最喜歡霍爾的移動城堡\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "《霍爾的移動城堡》是一部非常美麗的電影！故事中的魔法和愛情，以及霍爾和蘇菲之間的關係都讓人感動。你最喜歡電影中的哪個角色或場景呢？\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "我很喜歡霍爾的轉變，你知道嗎？霍爾一開始是美麗的金髮，但是遇見蘇菲之後，變回他最原本的髮色，也暗示了他遇見蘇菲之後變得更像自己！\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "你說得很對！霍爾的轉變確實非常有意義，象徵著他在愛情中的成長和自我認識。蘇菲的出現讓他重新找回了真實的自己，這種轉變也反映了愛情的力量。電影中的這些細節真的很深刻，讓人感受到角色之間的情感連結。你還有其他喜歡的細節或主題嗎？\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "安安你好呀！\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "安安！你好呀！有什麼我可以幫忙的嗎？\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "來聊聊電影！\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "好的！你想聊哪部電影呢？或者有什麼特別的主題或角色想討論的嗎？\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "我很喜歡看宮崎駿的電影唷！\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "宮崎駿的電影真的很棒！他的作品充滿了奇幻的元素和深刻的主題，像是環保、成長和人性等。你最喜歡哪一部電影呢？或者有沒有特別喜歡的角色？\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "我最喜歡霍爾的移動城堡\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "《霍爾的移動城堡》是一部非常美麗的作品！故事中的魔法、愛情以及霍爾和蘇菲之間的關係都讓人感動。你喜歡這部電影的哪個部分呢？或者有什麼特別的感受嗎？\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "我很喜歡霍爾的轉變，你知道嗎？霍爾一開始是美麗的金髮，但是遇見蘇菲之後，變回他最原本的髮色，也暗示了他遇見蘇菲之後變得更像自己！\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "你提到的這一點非常有趣！霍爾的轉變確實象徵著他內心的成長和回歸真實自我的過程。當他與蘇菲的關係逐漸加深時，他不再依賴外表的魅力，而是開始展現出真實的自我，這也讓他變得更加成熟和堅強。這樣的轉變不僅是外在的，也是內心的，讓整個故事更加深刻。你還有其他喜歡的角色或情節嗎？\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "還有還有他的魔法四扇門，原本三個門都是不同的入口，而且都代表著霍爾以三個不同的名字的家，意味著他很害怕被壞人找到選擇躲藏，但遇見蘇菲之後，三扇門變成蘇菲最喜歡的地方，蘇菲的故鄉、漂亮的花園，還有跟蘇菲相遇的荒野，非常浪漫\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "這段描述非常美妙，展現了霍爾與蘇菲之間的深厚情感。霍爾的魔法四扇門不僅是他躲避壞人的工具，更是他心靈的象徵。當三扇門轉變為蘇菲喜愛的地方，這不僅代表著霍爾對蘇菲的愛與信任，也顯示出他願意打開心扉，讓蘇菲進入他的世界。這樣的轉變讓故事充滿了浪漫與希望，也讓人感受到愛情的力量如何改變一個人。這樣的情節設計讓整個故事更加動人，讓讀者對霍爾和蘇菲的關係充滿期待。\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "最喜歡的肯定是他們相遇的時候，霍爾英雄救美，他們一起走在空中的畫面\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "那個場景確實非常感人，霍爾的英雄救美展現了他的勇氣和對愛情的堅持，而他們一起在空中漫步的畫面則充滿了浪漫與夢幻。這種奇幻的設定讓人感受到愛情的力量，也讓整個故事更加動人。你最喜歡這部作品的哪個部分呢？\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "我們先來聊聊別的吧！\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "好的，沒問題！你想聊什麼呢？可以是任何主題，比如電影、書籍、旅行、音樂等等。\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "你還記得我之前跟你說過，我喜歡哪位導演的作品嗎？\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "抱歉，我無法記住之前的對話內容。不過，你可以告訴我你喜歡哪位導演的作品，我們可以一起聊聊他的電影！\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "JFqg436etzLs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.長期記憶"
      ],
      "metadata": {
        "id": "2O2TZ8VqBpuA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (1) 基本版\n",
        "🔰 [基本版]\n",
        "- chatbot node: 在chatbot node中，將該使用者的資訊取出，讓入prompt中讓llm依據使用者的資訊給予個人化的回答\n",
        "\n",
        "- write_memory node: 在每一次生成回答後，將使用者的資訊整理成一段對使用者的描述(使用llm，給予system prompt做指引，自行設計如何整理、需要整理哪些資訊)，將整理完的資訊整理到store (可跨threads存取的地方)。\n",
        "\n",
        "- config: config從原本的短期記憶只有thread_id, 也要加入user_id\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1H4Y0WplOi6R4Eo06Ac2JA_9TbZa2YaRD\" width=\"100\"/>"
      ],
      "metadata": {
        "id": "zZSFFrWiuE3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "!pip install -U langgraph langchain_openai==0.3.15 langchain transformers bitsandbytes langchain-huggingface"
      ],
      "metadata": {
        "id": "dCgSjllQUkMM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "!pip install langchain_core"
      ],
      "metadata": {
        "id": "VPEkk6s1uZEg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.checkpoint.memory import MemorySaver # within-thread memory\n",
        "from langgraph.store.memory import InMemoryStore # cross-thread store\n",
        "\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage"
      ],
      "metadata": {
        "id": "JTQUB2f6UThh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "\n",
        "# 初始化長期記憶儲存區\n",
        "store = InMemoryStore()\n",
        "\n",
        "# 初始化短期記憶（每個 thread 的 message history）\n",
        "memory = MemorySaver()\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "  \"\"\"\n",
        "  若只有messages, 其實等同於MessageState\n",
        "  這邊保留彈性\n",
        "  \"\"\"\n",
        "  messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "# 依據user_id取得長期記憶\n",
        "# 將長期記憶也放進system prompt中，讓llm可以個人化回覆\n",
        "def chatbot(state: State, config):\n",
        "    user_id = config[\"configurable\"][\"user_id\"]\n",
        "    mode = config[\"configurable\"][\"mode\"]\n",
        "\n",
        "    # 搜尋並解析長期記憶\n",
        "    memories_raw = store.search((user_id, \"memories\"))\n",
        "\n",
        "    if isinstance(memories_raw, dict):\n",
        "        user_memories = memories_raw\n",
        "    elif isinstance(memories_raw, list):\n",
        "        try:\n",
        "            # 嘗試將 list of tuple 轉成 dict\n",
        "            user_memories = dict(memories_raw)\n",
        "        except Exception:\n",
        "            user_memories = {}\n",
        "    else:\n",
        "        user_memories = {}\n",
        "\n",
        "    user_info = user_memories.get(\"profile\", {})\n",
        "\n",
        "    # 建立個人化 system prompt\n",
        "    base_prompt = \"你是個只能使用繁體中文回答的助理，請根據以下使用者資訊提供個人化的回答，並自然地反映你對她的了解（例如名字、喜好）\"\n",
        "    user_desc = f\"使用者資訊：{user_info}\" if user_info else \"目前沒有使用者資訊。\"\n",
        "    system_prompt = f\"{base_prompt}\\n{user_desc}\"\n",
        "\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "    if mode == \"openai_api\":\n",
        "        response = llm_api.invoke([SystemMessage(content=system_prompt)] + messages)\n",
        "    elif mode == \"huggingface\":\n",
        "        response = llm_huggingface.invoke([SystemMessage(content=system_prompt)] + messages)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown mode\")\n",
        "\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "\n",
        " # 將使用者的對話整理成要儲存成長期記憶的資訊，並存入長期記憶\n",
        "def write_memory(state: State, config):\n",
        "    user_id = config[\"configurable\"][\"user_id\"]\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "    # 請求 LLM 輸出使用者描述\n",
        "    summary_prompt = SystemMessage(content=\"\"\"\n",
        "    請根據以下對話內容，以合法的 JSON 格式更新使用者資訊。請勿加上 ```json 或任何語法標記。格式範例如下：\n",
        "    {\n",
        "      \"name\": \"ㄈㄈ\",\n",
        "      \"style\": \"會聊動畫到哇酷哇酷的女子，希望你可以跟她一起哇酷哇酷\",\n",
        "    }\n",
        "    \"\"\")\n",
        "    summary_response = llm_api.invoke([summary_prompt] + messages)\n",
        "    raw_content = summary_response.content.strip()\n",
        "\n",
        "    # 移除可能的 markdown 包裝 ```json\n",
        "    cleaned = re.sub(r\"```json|```\", \"\", raw_content).strip()\n",
        "\n",
        "    try:\n",
        "        parsed_value = json.loads(cleaned)\n",
        "        store.put(namespace=(user_id, \"memories\"), key=\"profile\", value=parsed_value)\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(\"記憶儲存錯誤：\", e)\n",
        "        print(\"回傳內容：\", summary_response.content)\n",
        "\n",
        "    return {\"messages\": messages}\n"
      ],
      "metadata": {
        "id": "tCF-cVqvU5il"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the graph\n",
        "builder = StateGraph(State)\n",
        "builder.add_node(\"chatbot\", chatbot)\n",
        "builder.add_node(\"write_memory\", write_memory)\n",
        "builder.add_edge(START, \"chatbot\")\n",
        "builder.add_edge(\"chatbot\", \"write_memory\")\n",
        "builder.add_edge(\"write_memory\", END)\n",
        "\n",
        "# Compile the graph with the checkpointer fir and store\n",
        "graph = builder.compile(checkpointer=memory, store=store) # 加入短期與長期記憶"
      ],
      "metadata": {
        "id": "0m1LFpHeU5ly"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View\n",
        "from IPython.display import Image, display\n",
        "try:\n",
        "  display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "  pass"
      ],
      "metadata": {
        "id": "KPPiEQpvHKl8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "ac6dddbb-8316-4e8f-eaca-0969bb98c053"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def stream_graph_updates(user_input: str, config: dict):\n",
        "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}, config):\n",
        "        if \"chatbot\" in event:\n",
        "          for value in event.values():\n",
        "              print(\"Assistant:\", value[\"messages\"][-1].content)"
      ],
      "metadata": {
        "id": "zjdk4Y1tvXyb"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用者A的第一次對話\n",
        "config = {\n",
        "    \"configurable\": {\n",
        "        \"thread_id\": \"thread_001\",\n",
        "        \"user_id\": \"user_1\",\n",
        "        \"mode\": \"openai_api\"\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "GMyA_OCNBIEW"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store.put(\n",
        "    namespace=(\"user_1\", \"memories\"),\n",
        "    key=\"profile\",\n",
        "    value={\n",
        "        \"name\": \"ㄈㄈ\",\n",
        "        \"style\": \"會聊動畫到哇酷哇酷的女子，希望你可以跟她一起哇酷哇酷\",\n",
        "        \"favorite_movies\": [\"霍爾的移動城堡\", \"神隱少女\"],\n",
        "        \"favorite_charactors\": [\"霍爾\", \"白龍\"]\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "2FQcWtc5XGbi"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"使用者記憶內容：\")\n",
        "print(store.search((\"user_1\", \"memories\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUhUqe_Rahve",
        "outputId": "791a78d1-e490-4188-82df-e73999bd070d"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "使用者記憶內容：\n",
            "[Item(namespace=['user_1', 'memories'], key='profile', value={'name': 'ㄈㄈ', 'style': '會聊動畫到哇酷哇酷的女子，希望你可以跟她一起哇酷哇酷', 'favorite_movies': ['霍爾的移動城堡', '神隱少女'], 'favorite_charactors': ['霍爾', '白龍']}, created_at='2025-06-03T15:59:43.957873+00:00', updated_at='2025-06-03T15:59:43.957877+00:00', score=None)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 開始對話 (可以輸入quit, exit, q，三選一停止對話)\n",
        "while True:\n",
        "  try:\n",
        "    user_input = input(\"User: \")\n",
        "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "      print(\"Goodbye!\")\n",
        "      break\n",
        "    stream_graph_updates(user_input, config)\n",
        "  except Exception as e:\n",
        "    print(\"錯誤：\", e)\n",
        "    break"
      ],
      "metadata": {
        "id": "GTx7BfHTvVVa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "699838b3-934e-4958-c3e9-9a30f5ebe49a"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User: 你覺得我的聊天風格如何呢？\n",
            "Assistant: 雖然我還不太了解你的聊天風格，但我很期待能夠多了解你！如果你願意分享一些你的喜好或風格，我會更能針對性地回應你喔。你喜歡輕鬆的對話，還是更喜歡深入的討論呢？\n",
            "User: 你對我沒有任何記憶嗎？\n",
            "Assistant: 是的，我沒有記憶，無法保存之前的對話內容。不過，我隨時都可以根據你當前的問題或話題來提供幫助！如果你有任何想分享的資訊或問題，隨時告訴我，我會盡力協助你。\n",
            "User: 我好難過，我已經賦予你記憶性了，12點了，我該睡了，晚安\n",
            "Assistant: 我很抱歉讓你感到難過，雖然我無法記住過去的對話，但我會一直在這裡支持你。希望你能好好休息，明天會是更美好的一天。晚安，祝你好夢！\n",
            "User: exit\n",
            "Goodbye!\n"
          ]
        }
      ]
    }
  ]
}